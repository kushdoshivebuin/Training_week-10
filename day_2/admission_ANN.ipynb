{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Admission_Predict_Ver1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 9)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Serial No.         500 non-null    int64  \n",
      " 1   GRE Score          500 non-null    int64  \n",
      " 2   TOEFL Score        500 non-null    int64  \n",
      " 3   University Rating  500 non-null    int64  \n",
      " 4   SOP                500 non-null    float64\n",
      " 5   LOR                500 non-null    float64\n",
      " 6   CGPA               500 non-null    float64\n",
      " 7   Research           500 non-null    int64  \n",
      " 8   Chance of Admit    500 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 35.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Serial No.'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n",
       "0        337          118                  4  4.5   4.5  9.65         1   \n",
       "1        324          107                  4  4.0   4.5  8.87         1   \n",
       "2        316          104                  3  3.0   3.5  8.00         1   \n",
       "3        322          110                  3  3.5   2.5  8.67         1   \n",
       "4        314          103                  2  2.0   3.0  8.21         0   \n",
       "\n",
       "   Chance of Admit   \n",
       "0              0.92  \n",
       "1              0.76  \n",
       "2              0.72  \n",
       "3              0.80  \n",
       "4              0.65  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 0:-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin-\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(7, activation='relu', input_dim = 7))\n",
    "model.add(Dense(7, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m8\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">120</span> (480.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m120\u001b[0m (480.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.2804 - val_loss: 0.1740\n",
      "Epoch 2/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.1343 - val_loss: 0.0712\n",
      "Epoch 3/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0583 - val_loss: 0.0312\n",
      "Epoch 4/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0223 - val_loss: 0.0293\n",
      "Epoch 5/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0181 - val_loss: 0.0307\n",
      "Epoch 6/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0211 - val_loss: 0.0257\n",
      "Epoch 7/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0192 - val_loss: 0.0218\n",
      "Epoch 8/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0160 - val_loss: 0.0201\n",
      "Epoch 9/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0156 - val_loss: 0.0191\n",
      "Epoch 10/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0157 - val_loss: 0.0186\n",
      "Epoch 11/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0144 - val_loss: 0.0181\n",
      "Epoch 12/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 13/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0120 - val_loss: 0.0164\n",
      "Epoch 14/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0136 - val_loss: 0.0158\n",
      "Epoch 15/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0131 - val_loss: 0.0151\n",
      "Epoch 16/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0155 - val_loss: 0.0145\n",
      "Epoch 17/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0138 - val_loss: 0.0141\n",
      "Epoch 18/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 19/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0127 - val_loss: 0.0130\n",
      "Epoch 20/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 21/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 22/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0123 - val_loss: 0.0116\n",
      "Epoch 23/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 24/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0094 - val_loss: 0.0112\n",
      "Epoch 25/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0093 - val_loss: 0.0107\n",
      "Epoch 26/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0091 - val_loss: 0.0103\n",
      "Epoch 27/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 28/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 29/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 30/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0081 - val_loss: 0.0092\n",
      "Epoch 31/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0093 - val_loss: 0.0090\n",
      "Epoch 32/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 33/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 34/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 35/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0084 - val_loss: 0.0081\n",
      "Epoch 36/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0088 - val_loss: 0.0079\n",
      "Epoch 37/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 38/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0080 - val_loss: 0.0076\n",
      "Epoch 39/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0068 - val_loss: 0.0075\n",
      "Epoch 40/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 41/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0073 - val_loss: 0.0071\n",
      "Epoch 42/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 43/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 44/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 45/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 46/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 47/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0068 - val_loss: 0.0065\n",
      "Epoch 48/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0063 - val_loss: 0.0064\n",
      "Epoch 49/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 50/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0059 - val_loss: 0.0062\n",
      "Epoch 51/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 52/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 53/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 54/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 55/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 56/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0061 - val_loss: 0.0058\n",
      "Epoch 57/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0068 - val_loss: 0.0058\n",
      "Epoch 58/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 59/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 60/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 61/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - val_loss: 0.0056\n",
      "Epoch 62/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0063 - val_loss: 0.0055\n",
      "Epoch 63/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 64/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0065 - val_loss: 0.0055\n",
      "Epoch 65/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 66/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 67/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 68/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 69/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0052\n",
      "Epoch 70/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 71/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0063 - val_loss: 0.0052\n",
      "Epoch 72/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 73/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0059 - val_loss: 0.0051\n",
      "Epoch 74/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - val_loss: 0.0051\n",
      "Epoch 75/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 76/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 77/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 78/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 79/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Epoch 80/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 81/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 82/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 83/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 84/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0049 - val_loss: 0.0049\n",
      "Epoch 85/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 86/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 87/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 88/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 89/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 90/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 91/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 92/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 93/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 94/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 95/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0050 - val_loss: 0.0046\n",
      "Epoch 96/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 97/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0054 - val_loss: 0.0046\n",
      "Epoch 98/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 99/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 100/100\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0053 - val_loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001A412022020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/stepWARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001A412022020> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7163906082607148"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a41215f710>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
